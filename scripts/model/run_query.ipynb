{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pprint\n",
    "from helper import clean_name, extract_officer_data, summarize_context, generate_hypothetical_embeddings, f_path, PROMPT_TEMPLATE_HYDE\n",
    "\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "query_memory = []\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 250\n",
    "TEMPERATURE = 0\n",
    "k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT_TEMPLATE_MODEL = PromptTemplate(\n",
    "    input_variables=[\"question\", \"docs\"],\n",
    "    template=\"\"\"\n",
    "    As an AI assistant, my role is to meticulously analyze court transcripts and extract information about law enforcement personnel.\n",
    "    The names of law enforcement personnel will be prefixed by one of the following titles: officer, detective, deputy, lieutenant, \n",
    "    sergeant, captain, officer, coroner, investigator, criminalist, patrolman, or technician.\n",
    "\n",
    "    Query: {question}\n",
    "\n",
    "    Transcripts: {docs}\n",
    "\n",
    "    The response will contain:\n",
    "\n",
    "    1) The name of a officer, detective, deputy, lieutenant, \n",
    "       sergeant, captain, officer, coroner, investigator, criminalist, patrolman, or technician - \n",
    "       if an individual's name is not associated with one of these titles they do not work in law enforcement.\n",
    "       Please prefix the name with \"Officer Name: \". \n",
    "       For example, \"Officer Name: John Smith\".\n",
    "\n",
    "    2) If available, provide an in-depth description of the context of their mention. \n",
    "       If the context induces ambiguity regarding the individual's employment in law enforcement, \n",
    "       remove the individual.\n",
    "       Please prefix this information with \"Officer Context: \". \n",
    "\n",
    "    Continue this pattern of identifying persons, until all law enforcement personnel are identified.  \n",
    "\n",
    "    Additional guidelines for the AI assistant:\n",
    "    - Titles may be abbreviated to the following Sgt., Cpl, Cpt, Det., Ofc., Lt., P.O. and P/O\n",
    "    - Titles \"Technician\" and \"Tech\" might be used interchangeably.\n",
    "    - Derive responses from factual information found within the police reports.\n",
    "    - If the context of an identified person's mention is not clear in the report, provide their name and note that the context is not specified.\n",
    "    - Do not extract information about victims and witnesses\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(file_path, embeddings):\n",
    "    logger.info(f\"Processing Word document: {file_path}\")\n",
    "\n",
    "    loader = Docx2txtLoader(file_path)\n",
    "    text = loader.load()\n",
    "    logger.info(f\"Text loaded from Word document: {file_path}\")\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "    docs = text_splitter.split_documents(text)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_response_from_query(db, query, temperature, k):\n",
    "    logger.info(\"Performing query...\")\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    pprint.pprint(docs)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "    pprint.pprint(docs_page_content)\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE_MODEL\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    response = chain.run(question=query, docs=docs_page_content, temperature=temperature)\n",
    "\n",
    "    formatted_response = \"\"\n",
    "    officers = response.split(\"Officer Name:\")\n",
    "    for i, officer in enumerate(officers):\n",
    "        if officer.strip() != \"\":\n",
    "            formatted_response += f\"Officer Name {i}:{officer.replace('Officer Context:', 'Officer Context ' + str(i) + ':')}\\n\\n\"\n",
    "\n",
    "    officer_data = extract_officer_data(formatted_response)\n",
    "    return officer_data, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    \"Identify individuals, by name, with the specific titles of officers, sergeants, lieutenants, captains, detectives, homicide officers, and crime lab personnel in the transcript. Specifically, provide the context of their mention related to key events in the case, if available.\",\n",
    "    \"List individuals, by name, directly titled as officers, sergeants, lieutenants, captains, detectives, homicide units, and crime lab personnel mentioned in the transcript. Provide the context of their mention in terms of any significant decisions they made or actions they took.\",\n",
    "    \"Locate individuals, by name, directly referred to as officers, sergeants, lieutenants, captains, detectives, homicide units, and crime lab personnel in the transcript. Explain the context of their mention in relation to their interactions with other individuals in the case.\",\n",
    "    \"Highlight individuals, by name, directly titled as officers, sergeants, lieutenants, captains, detectives, homicide units, and crime lab personnel in the transcript. Describe the context of their mention, specifically noting any roles or responsibilities they held in the case.\",\n",
    "    \"Outline individuals, by name, directly identified as officers, sergeants, lieutenants, captains, detectives, homicide units, and crime lab personnel in the transcript. Specify the context of their mention in terms of any noteworthy outcomes or results they achieved.\",\n",
    "    \"Pinpoint individuals, by name, directly labeled as officers, sergeants, lieutenants, captains, detectives, homicide units, and crime lab personnel in the transcript. Provide the context of their mention, particularly emphasizing any significant incidents or episodes they were involved in.\",\n",
    "\n",
    "]\n",
    "\n",
    "def process_query(embeddings):\n",
    "    for file_name in os.listdir(f_path):\n",
    "        if file_name.endswith(\".docx\"):\n",
    "            csv_output_path = os.path.join(f_path, f\"{file_name}.csv\")\n",
    "            if os.path.exists(csv_output_path):\n",
    "                logger.info(f\"CSV output for {file_name} already exists. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(f_path, file_name)\n",
    "            output_data = []\n",
    "\n",
    "            db = preprocess_document(file_path, embeddings)\n",
    "            for query in QUERIES:\n",
    "                officer_data, _ = get_response_from_query(db, query, TEMPERATURE, k)\n",
    "                for item in officer_data:\n",
    "                    item[\"Query\"] = query\n",
    "                    item[\"Prompt Template for Hyde\"] = PROMPT_TEMPLATE_HYDE\n",
    "                    item[\"Prompt Template for Model\"] = PROMPT_TEMPLATE_MODEL\n",
    "                    item[\"Chunk Size\"] = CHUNK_SIZE\n",
    "                    item[\"Chunk Overlap\"] = CHUNK_OVERLAP\n",
    "                    item[\"Temperature\"] = TEMPERATURE\n",
    "                    item[\"k\"] = k\n",
    "                    item[\"hyde\"] = \"1\"\n",
    "                output_data.extend(officer_data)\n",
    "\n",
    "            output_df = pd.DataFrame(output_data)\n",
    "            output_df.to_csv(csv_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    embeddings = generate_hypothetical_embeddings()\n",
    "    process_query(embeddings)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
