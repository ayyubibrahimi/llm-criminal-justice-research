{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "from langchain import PromptTemplate\n",
    "from helper import generate_hypothetical_embeddings, preprocess_single_document, get_response_from_query, f_path, PROMPT_TEMPLATE_MODEL\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "query_memory = []\n",
    "\n",
    "\n",
    "embeddings = generate_hypothetical_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_MODEL = PromptTemplate(\n",
    "    input_variables=[\"question\", \"docs\"],\n",
    "    template=\"\"\"\n",
    "    As an AI assistant, my role is to meticulously analyze court transcripts and extract information about law enforcement personnel.\n",
    "    The names of law enforcement personnel will be prefixed by one of the following titles: officer, detective, deputy, lieutenant, \n",
    "    sergeant, captain, officer, coroner, investigator, criminalist, patrolman, or technician.\n",
    "\n",
    "    Query: {question}\n",
    "\n",
    "    Transcripts: {docs}\n",
    "\n",
    "    The response will contain:\n",
    "\n",
    "    1) The name of a officer, detective, deputy, lieutenant, \n",
    "       sergeant, captain, officer, coroner, investigator, criminalist, patrolman, or technician - \n",
    "       if an individual's name is not associated with one of these titles they do not work in law enforcement.\n",
    "       Please prefix the name with \"Officer Name: \". \n",
    "       For example, \"Officer Name: John Smith\".\n",
    "\n",
    "    2) If available, provide an in-depth description of the context of their mention. \n",
    "       If the context induces ambiguity regarding the individual's employment in law enforcement, \n",
    "       remove the individual.\n",
    "       Please prefix this information with \"Officer Context: \". \n",
    "\n",
    "    Continue this pattern of identifying persons, until all law enforcement personnel are identified.  \n",
    "\n",
    "    Additional guidelines for the AI assistant:\n",
    "    - Titles may be abbreviated to the following Sgt., Cpl, Cpt, Det., Ofc., Lt., P.O. and P/O\n",
    "    - Titles \"Technician\" and \"Tech\" might be used interchangeably.\n",
    "    - Derive responses from factual information found within the police reports.\n",
    "    - If the context of an identified person's mention is not clear in the report, provide their name and note that the context is not specified.\n",
    "    - Do not extract information about victims and witnesses\n",
    "\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    \"Identify individuals, by name, with the specific titles of officers, sergeants, lieutenants, captains, detectives, homicide officers, and crime lab personnel in the transcript. Specifically, provide the context of their mention related to key events in the case, if available.\",\n",
    "]\n",
    "\n",
    "def preprocess_documents_in_directory(directory_path, embeddings, chunk_size, chunk_overlap):\n",
    "    dbs = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.docx'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            db = preprocess_single_document(file_path, embeddings, chunk_size, chunk_overlap)\n",
    "            dbs.append(db)\n",
    "            \n",
    "    return dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:47:35,794 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:47:35,828 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | chunk_... | chunk_... |     k     |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:47:38,972 - INFO - Loading faiss with AVX2 support.\n",
      "2023-07-26 12:47:38,973 - INFO - Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "2023-07-26 12:47:38,973 - INFO - Loading faiss.\n",
      "2023-07-26 12:47:38,994 - INFO - Successfully loaded faiss.\n",
      "2023-07-26 12:47:39,018 - INFO - Performing query...\n",
      "2023-07-26 12:48:25,302 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:48:25,331 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m328.0    \u001b[0m | \u001b[0m2.126e+03\u001b[0m | \u001b[0m5.161e+03\u001b[0m | \u001b[0m1.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:48:28,553 - INFO - Performing query...\n",
      "2023-07-26 12:48:43,662 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:48:43,692 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.953e+03\u001b[0m | \u001b[0m3.44e+03 \u001b[0m | \u001b[0m1.369    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:48:45,873 - INFO - Performing query...\n",
      "2023-07-26 12:49:23,558 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m276.0    \u001b[0m | \u001b[0m2.131e+03\u001b[0m | \u001b[0m5.164e+03\u001b[0m | \u001b[0m1.228    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:49:23,763 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:49:26,404 - INFO - Performing query...\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "2023-07-26 12:50:16,955 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:50:16,985 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m266.0    \u001b[0m | \u001b[0m2.102e+03\u001b[0m | \u001b[0m5.169e+03\u001b[0m | \u001b[0m1.723    \u001b[0m |\n",
      "=============================================================\n",
      "|   iter    |  target   | chunk_... | chunk_... |     k     |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:50:22,181 - INFO - Performing query...\n",
      "2023-07-26 12:50:51,845 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:50:51,876 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m203.0    \u001b[0m | \u001b[0m1.417e+03\u001b[0m | \u001b[0m2.58e+03 \u001b[0m | \u001b[0m1.001    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:50:57,545 - INFO - Performing query...\n",
      "2023-07-26 12:51:36,340 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:51:36,372 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m2        \u001b[0m | \u001b[95m216.0    \u001b[0m | \u001b[95m1.302e+03\u001b[0m | \u001b[95m1.72e+03 \u001b[0m | \u001b[95m1.831    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:51:42,120 - INFO - Performing query...\n",
      "2023-07-26 12:51:53,144 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:51:53,176 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.299e+03\u001b[0m | \u001b[0m1.731e+03\u001b[0m | \u001b[0m1.701    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:51:59,209 - INFO - Performing query...\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "2023-07-26 12:52:18,552 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:52:18,584 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m99.0     \u001b[0m | \u001b[0m1.308e+03\u001b[0m | \u001b[0m1.721e+03\u001b[0m | \u001b[0m2.163    \u001b[0m |\n",
      "=============================================================\n",
      "|   iter    |  target   | chunk_... | chunk_... |     k     |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:52:21,241 - INFO - Performing query...\n",
      "2023-07-26 12:52:46,709 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m37.0     \u001b[0m | \u001b[0m354.3    \u001b[0m | \u001b[0m1.29e+03 \u001b[0m | \u001b[0m1.004    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:52:46,916 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:52:50,090 - INFO - Performing query...\n",
      "2023-07-26 12:53:29,539 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:53:29,570 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m2        \u001b[0m | \u001b[95m285.0    \u001b[0m | \u001b[95m325.6    \u001b[0m | \u001b[95m860.1    \u001b[0m | \u001b[95m4.601    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:53:32,891 - INFO - Performing query...\n",
      "2023-07-26 12:54:24,292 - INFO - Processing Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m270.0    \u001b[0m | \u001b[0m322.7    \u001b[0m | \u001b[0m861.9    \u001b[0m | \u001b[0m6.143    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:54:24,324 - INFO - Text loaded from Word document: ../../data/convictions/transcripts/evaluate\\Adams_Exhibit Volumes FILED.docx\n",
      "2023-07-26 12:54:29,462 - INFO - Performing query...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m61.0     \u001b[0m | \u001b[0m368.8    \u001b[0m | \u001b[0m832.9    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\ayyubi\\AppData\\Local\\Temp\\ipykernel_12816\\1741658090.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "pbounds_list = [\n",
    "    {\n",
    "        'chunk_size': (3000, 6000),\n",
    "        'chunk_overlap': (1500, 3000),\n",
    "        'k': (1, 5),\n",
    "    },\n",
    "    {\n",
    "        'chunk_size': (1500, 3000),\n",
    "        'chunk_overlap': (1000, 2000),\n",
    "        'k': (1, 10),\n",
    "    },\n",
    "    {\n",
    "        'chunk_size': (750, 1500),\n",
    "        'chunk_overlap': (250, 500),\n",
    "        'k': (1, 40),\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def objective(chunk_size, chunk_overlap, k):\n",
    "    dbs = preprocess_documents_in_directory(f_path, embeddings, chunk_size, chunk_overlap)\n",
    "    \n",
    "    total_token_count = sum(get_response_from_query(db, query, k) for db in dbs)\n",
    "\n",
    "    return total_token_count\n",
    "\n",
    "\n",
    "def sample_posterior(optimizer, param_bounds, n_samples=100):\n",
    "    x_samples = np.linspace(param_bounds['chunk_size'][0], param_bounds['chunk_size'][1], num=n_samples)\n",
    "    y_samples = np.linspace(param_bounds['chunk_overlap'][0], param_bounds['chunk_overlap'][1], num=n_samples)\n",
    "    x_grid, y_grid = np.meshgrid(x_samples, y_samples)\n",
    "    xy_samples = np.stack([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    k = np.full((xy_samples.shape[0], 1), optimizer.max['params']['k'])\n",
    "    xyk_samples = np.concatenate([xy_samples, k], axis=1)\n",
    "\n",
    "    mu, sigma = optimizer._gp.predict(xyk_samples, return_std=True)\n",
    "\n",
    "    f_samples = np.random.normal(loc=mu, scale=sigma, size=(n_samples, len(xyk_samples)))\n",
    "\n",
    "    return xy_samples, f_samples\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Query', 'Chunk_Size', 'Chunk_Overlap', 'k', 'Tokens'])\n",
    "\n",
    "for pbounds in pbounds_list:\n",
    "    for query in QUERIES:\n",
    "        optimizer = BayesianOptimization(\n",
    "            f=objective,\n",
    "            pbounds=pbounds,\n",
    "            verbose=2, \n",
    "            random_state=1,\n",
    "        )\n",
    "\n",
    "        optimizer.maximize(\n",
    "            init_points=2,\n",
    "            n_iter=2,\n",
    "        )\n",
    "\n",
    "        for res in optimizer.res:\n",
    "            results_df = results_df.append({\n",
    "                'Query': query, \n",
    "                'Chunk_Size': res['params']['chunk_size'], \n",
    "                'Chunk_Overlap': res['params']['chunk_overlap'], \n",
    "                'k': res['params']['k'], \n",
    "                'Tokens': res['target']}, ignore_index=True)\n",
    "\n",
    "        xy_samples, f_samples = sample_posterior(optimizer, pbounds)\n",
    "\n",
    "        f_samples = f_samples.flatten()\n",
    "\n",
    "        mean_tokens = np.mean(f_samples)\n",
    "        variance_tokens = np.var(f_samples)\n",
    "\n",
    "        results_df = results_df.append({\n",
    "            \"Query\": query,\n",
    "            \"Sampled_Chunk_Size_Mean\": np.mean(xy_samples[:, 0]),\n",
    "            \"Sampled_Chunk_Size_Variance\": np.var(xy_samples[:, 0]),\n",
    "            \"Sampled_Chunk_Overlap_Mean\": np.mean(xy_samples[:, 1]),\n",
    "            \"Sampled_Chunk_Overlap_Variance\": np.var(xy_samples[:, 1]),\n",
    "            \"Sampled_k\": optimizer.max[\"params\"][\"k\"],\n",
    "            \"Sampled_Tokens_Mean\": mean_tokens,\n",
    "            \"Sampled_Tokens_Variance\": variance_tokens,\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('output/optimization_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
