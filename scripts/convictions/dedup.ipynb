{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 14:31:07,443 - INFO - CSV output for (J) NOPD Supplemental Report J-7239-79 (2).docx already exists. Skipping...\n",
      "2023-07-10 14:31:07,444 - INFO - CSV output for 05 NOPD Supplemental Report.docx already exists. Skipping...\n",
      "2023-07-10 14:31:07,445 - INFO - CSV output for 1. Supplemental Report.docx already exists. Skipping...\n",
      "2023-07-10 14:31:07,446 - INFO - Processing Word document: ../../data/convictions/evaluate/reports\\18. Supplemental Report (includes Arrest Reports) --.docx\n",
      "2023-07-10 14:31:07,469 - INFO - Text loaded from Word document: ../../data/convictions/evaluate/reports\\18. Supplemental Report (includes Arrest Reports) --.docx\n",
      "2023-07-10 14:31:08,400 - INFO - Performing query...\n",
      "2023-07-10 14:31:25,396 - INFO - Performing query...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot response for query:  Enumerate all law enforcement personnel, including police officers, sergeants, lieutentants, captains, detectives, homicide officers, crime lab personnel, and district attorneys from the transcript and provide the context of their mention, if available.\n",
      "[{'Officer Name': 'James Stewart', 'Officer Context': 'Detective James Stewart\n",
      "escorted BORDERE to the homicide office and inquired about his relationship with\n",
      "ROBERT JONES. Stewart also interviewed DONALD OLIVER regarding the information\n",
      "provided by an informant. Stewart later fielded a phone call from an anonymous female\n",
      "and instructed another officer to interview PERNELL HARRIS about the events of the\n",
      "homicide and the conversation at the barroom.', 'Officer Title': 'Detective',\n",
      "'Query': 'Enumerate all law enforcement personnel, including police officers,\n",
      "sergeants, lieutentants, captains, detectives, homicide officers, crime lab\n",
      "personnel, and district attorneys from the transcript and provide the context of\n",
      "their mention, if available.'}, {'Officer Name': 'Robert Jones', 'Officer Context':\n",
      "'Robert Jones was mentioned in relation to his presence in the barroom with BORDERE\n",
      "and JONES. He corroborated being in the barroom but denied discussing or knowing\n",
      "about any murder.', 'Officer Title': '', 'Query': 'Enumerate all law enforcement\n",
      "personnel, including police officers, sergeants, lieutentants, captains, detectives,\n",
      "homicide officers, crime lab personnel, and district attorneys from the transcript\n",
      "and provide the context of their mention, if available.'}, {'Officer Name':\n",
      "'Christopher Bordere', 'Officer Context': 'Christopher Bordere was interviewed by\n",
      "Detective Stewart in the homicide office. He explained that he and ROBERT JONES had\n",
      "been friends for many years and stated that he was in the barroom talking to several\n",
      "girls and playing video games but was not with ROBERT JONES. Bordere maintained that\n",
      "he was unaware of any conversation or murder.', 'Officer Title': 'C', 'Query':\n",
      "'Enumerate all law enforcement personnel, including police officers, sergeants,\n",
      "lieutentants, captains, detectives, homicide officers, crime lab personnel, and\n",
      "district attorneys from the transcript and provide the context of their mention, if\n",
      "available.'}, {'Officer Name': 'Donald Oliver', 'Officer Context': 'Donald Oliver was\n",
      "interviewed by Detective Stewart regarding the information provided by an informant.\n",
      "Oliver stated that he was not in the bar room and did not know about the murder or\n",
      "any conversation regarding it. Oliver was later arrested as an accessory to murder\n",
      "after the fact.', 'Officer Title': 'l', 'Query': 'Enumerate all law enforcement\n",
      "personnel, including police officers, sergeants, lieutentants, captains, detectives,\n",
      "homicide officers, crime lab personnel, and district attorneys from the transcript\n",
      "and provide the context of their mention, if available.'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 14:31:46,141 - INFO - Performing query...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot response for query:  Can you list all individuals related to law enforcement such as police officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys mentioned in the transcript and elaborate on the context of their mention?\n",
      "[{'Officer Name': 'Stewart', 'Officer Context': \"STEWART escorted BORDERE to the\n",
      "homicide office and inquired about his relationship with ROBERT JONES. He also\n",
      "interviewed DONALD OLIVER regarding knowledge of the murder and the informant's\n",
      "information. Based on the investigation, STEWART elected to arrest JONES for the\n",
      "murder of STOTT, and OLIVER and BORDERE were arrested as accessories to murder after\n",
      "the fact.\", 'Officer Title': '', 'Query': 'Can you list all individuals related to\n",
      "law enforcement such as police officers, sergeants, lieutentants, captains,\n",
      "detectives, homicide units, crime lab personnel, and district attorneys mentioned in\n",
      "the transcript and elaborate on the context of their mention?'}, {'Officer Name':\n",
      "'Oliver', 'Officer Context': \"OLIVER was interviewed by STEWART regarding his\n",
      "knowledge of the murder and the informant's information. OLIVER stated that he was\n",
      "not in the bar room and did not know about the murder or any conversation pertaining\n",
      "to it. He was later arrested as an accessory to murder after the fact.\", 'Officer\n",
      "Title': 'l', 'Query': 'Can you list all individuals related to law enforcement such\n",
      "as police officers, sergeants, lieutentants, captains, detectives, homicide units,\n",
      "crime lab personnel, and district attorneys mentioned in the transcript and elaborate\n",
      "on the context of their mention?'}, {'Officer Name': 'Jones', 'Officer Context':\n",
      "\"JONES was positively identified by a witness who was robbed prior to the murder. He\n",
      "corroborated being in the bar room and in the company of BORDERE and JONES. Despite\n",
      "BORDERE's inconsistent statements, JONES was arrested for the murder of STOTT.\",\n",
      "'Officer Title': '', 'Query': 'Can you list all individuals related to law\n",
      "enforcement such as police officers, sergeants, lieutentants, captains, detectives,\n",
      "homicide units, crime lab personnel, and district attorneys mentioned in the\n",
      "transcript and elaborate on the context of their mention?'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 14:32:00,710 - INFO - Performing query...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot response for query:  Please produce a roster of all persons involved with law enforcement, including police officers,  sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys from the transcript and explain why they are mentioned, if stated.\n",
      "[{'Officer Name': 'Stewart', 'Officer Context': 'Stewart escorted BORDERE to the\n",
      "homicide office and inquired about his relationship with ROBERT JONES. Stewart also\n",
      "interviewed DONALD OLIVER and later elected to arrest JONES, OLIVER, and BORDERE as\n",
      "accessories to murder.', 'Officer Title': '', 'Query': 'Please produce a roster of\n",
      "all persons involved with law enforcement, including police officers,  sergeants,\n",
      "lieutentants, captains, detectives, homicide units, crime lab personnel, and district\n",
      "attorneys from the transcript and explain why they are mentioned, if stated.'},\n",
      "{'Officer Name': 'McCord', 'Officer Context': 'McCord contacted Stewart to inform him\n",
      "that PERNELL HARRIS had arrived at the homicide office. McCord was instructed to\n",
      "interview PAPRIS about the events of the homicide and the conversation pertaining to\n",
      "it that occurred at the barroom.', 'Officer Title': 'c', 'Query': 'Please produce a\n",
      "roster of all persons involved with law enforcement, including police officers,\n",
      "sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel,\n",
      "and district attorneys from the transcript and explain why they are mentioned, if\n",
      "stated.'}, {'Officer Name': 'Canal', 'Officer Context': 'Stewart met with Lt. L. J.\n",
      "Canal, the Commander of the Homicide Section, and learned about the organization of a\n",
      "Homicide/Robbery Task Force.', 'Officer Title': 'C', 'Query': 'Please produce a\n",
      "roster of all persons involved with law enforcement, including police officers,\n",
      "sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel,\n",
      "and district attorneys from the transcript and explain why they are mentioned, if\n",
      "stated.'}, {'Officer Name': 'Venezia', 'Officer Context': 'Lt. Martin Venezia was the\n",
      "Commander of the Homicide/Robbery Task Force.', 'Officer Title': '', 'Query': 'Please\n",
      "produce a roster of all persons involved with law enforcement, including police\n",
      "officers,  sergeants, lieutentants, captains, detectives, homicide units, crime lab\n",
      "personnel, and district attorneys from the transcript and explain why they are\n",
      "mentioned, if stated.'}, {'Officer Name': 'Rodrigue', 'Officer Context': 'Sat: Craig\n",
      "Rodrigue was a supervisor in the Homicide/Robbery Task Force.', 'Officer Title': '',\n",
      "'Query': 'Please produce a roster of all persons involved with law enforcement,\n",
      "including police officers,  sergeants, lieutentants, captains, detectives, homicide\n",
      "units, crime lab personnel, and district attorneys from the transcript and explain\n",
      "why they are mentioned, if stated.'}, {'Officer Name': 'Cade', 'Officer Context':\n",
      "'Detective Herman Cade was a member of the Homicide/Robbery Task Force.', 'Officer\n",
      "Title': 'C', 'Query': 'Please produce a roster of all persons involved with law\n",
      "enforcement, including police officers,  sergeants, lieutentants, captains,\n",
      "detectives, homicide units, crime lab personnel, and district attorneys from the\n",
      "transcript and explain why they are mentioned, if stated.'}, {'Officer Name':\n",
      "'Farve', 'Officer Context': 'Detective Yvonne Farve was a member of the\n",
      "Homicide/Robbery Task Force.', 'Officer Title': '', 'Query': 'Please produce a roster\n",
      "of all persons involved with law enforcement, including police officers,  sergeants,\n",
      "lieutentants, captains, detectives, homicide units, crime lab personnel, and district\n",
      "attorneys from the transcript and explain why they are mentioned, if stated.'},\n",
      "{'Officer Name': 'Sposito', 'Officer Context': 'Detective Michael Sposito was a\n",
      "member of the Homicide/Robbery Task Force.', 'Officer Title': 'p', 'Query': 'Please\n",
      "produce a roster of all persons involved with law enforcement, including police\n",
      "officers,  sergeants, lieutentants, captains, detectives, homicide units, crime lab\n",
      "personnel, and district attorneys from the transcript and explain why they are\n",
      "mentioned, if stated.'}, {'Officer Name': 'Coffee', 'Officer Context': 'Detective\n",
      "Debbie Coffee, assigned to the rape unit, informed Stewart about a similar\n",
      "description of a perpetrator in a recent rape case.', 'Officer Title': 'C', 'Query':\n",
      "'Please produce a roster of all persons involved with law enforcement, including\n",
      "police officers,  sergeants, lieutentants, captains, detectives, homicide units,\n",
      "crime lab personnel, and district attorneys from the transcript and explain why they\n",
      "are mentioned, if stated.'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 14:32:14,359 - INFO - Performing query...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot response for query:  Identify all the law enforcement entities, notably police officers, sergeants, lieutentants, captains,  detectives, homicide units, crime lab personnel, and district attorneys stated in the transcript and describe the reason for their mention, if specified.\n",
      "[{'Officer Name': 'Det. James Stewart', 'Officer Context': 'Det. James Stewart is\n",
      "mentioned multiple times in the transcript as the reporting officer in the homicide\n",
      "investigation. He is involved in coordinating interviews, gathering information, and\n",
      "making arrests in relation to the murder of STOTT. He is also part of the\n",
      "Homicide/Robbery Task Force organized to focus on certain robberies and gather\n",
      "evidence related to the STOTT murder.', 'Officer Title': '', 'Query': 'Identify all\n",
      "the law enforcement entities, notably police officers, sergeants, lieutentants,\n",
      "captains,  detectives, homicide units, crime lab personnel, and district attorneys\n",
      "stated in the transcript and describe the reason for their mention, if specified.'},\n",
      "{'Officer Name': 'Lt. J. Canal', 'Officer Context': 'Lt. L. J. Canal is mentioned as\n",
      "the Commander of the Homicide Section who informs Det. James Stewart about the\n",
      "organization of the Homicide/Robbery Task Force. He provides information about the\n",
      "purpose of the task force and its members.', 'Officer Title': 'L', 'Query': 'Identify\n",
      "all the law enforcement entities, notably police officers, sergeants, lieutentants,\n",
      "captains,  detectives, homicide units, crime lab personnel, and district attorneys\n",
      "stated in the transcript and describe the reason for their mention, if specified.'},\n",
      "{'Officer Name': 'Lt. Martin Venezia', 'Officer Context': 'Lt. Martin Venezia is\n",
      "mentioned as the Commander of the Homicide/Robbery Task Force.', 'Officer Title':\n",
      "'L', 'Query': 'Identify all the law enforcement entities, notably police officers,\n",
      "sergeants, lieutentants, captains,  detectives, homicide units, crime lab personnel,\n",
      "and district attorneys stated in the transcript and describe the reason for their\n",
      "mention, if specified.'}, {'Officer Name': 'Sat: Craig Rodrigue', 'Officer Context':\n",
      "'Sat: Craig Rodrigue is mentioned as a supervisor within the Homicide/Robbery Task\n",
      "Force.', 'Officer Title': 'C', 'Query': 'Identify all the law enforcement entities,\n",
      "notably police officers, sergeants, lieutentants, captains,  detectives, homicide\n",
      "units, crime lab personnel, and district attorneys stated in the transcript and\n",
      "describe the reason for their mention, if specified.'}, {'Officer Name': 'Det. Herman\n",
      "Cade', 'Officer Context': 'Det. Herman Cade is mentioned as a member of the\n",
      "Homicide/Robbery Task Force.', 'Officer Title': 'C', 'Query': 'Identify all the law\n",
      "enforcement entities, notably police officers, sergeants, lieutentants, captains,\n",
      "detectives, homicide units, crime lab personnel, and district attorneys stated in the\n",
      "transcript and describe the reason for their mention, if specified.'}, {'Officer\n",
      "Name': 'Det. Yvonne Farve', 'Officer Context': 'Det. Yvonne Farve is mentioned as a\n",
      "member of the Homicide/Robbery Task Force.', 'Officer Title': '', 'Query': 'Identify\n",
      "all the law enforcement entities, notably police officers, sergeants, lieutentants,\n",
      "captains,  detectives, homicide units, crime lab personnel, and district attorneys\n",
      "stated in the transcript and describe the reason for their mention, if specified.'},\n",
      "{'Officer Name': 'Det. MichaeSposito', 'Officer Context': 'Det. Michael Sposito is\n",
      "mentioned as a member of the Homicide/Robbery Task Force.', 'Officer Title': 'c',\n",
      "'Query': 'Identify all the law enforcement entities, notably police officers,\n",
      "sergeants, lieutentants, captains,  detectives, homicide units, crime lab personnel,\n",
      "and district attorneys stated in the transcript and describe the reason for their\n",
      "mention, if specified.'}, {'Officer Name': 'Det. Debbie Coffee', 'Officer Context':\n",
      "'Det. Debbie Coffee is mentioned as a detective assigned to the rape unit who informs\n",
      "Det. James Stewart about a similar description of a perpetrator in a recent rape\n",
      "case.', 'Officer Title': 'C', 'Query': 'Identify all the law enforcement entities,\n",
      "notably police officers, sergeants, lieutentants, captains,  detectives, homicide\n",
      "units, crime lab personnel, and district attorneys stated in the transcript and\n",
      "describe the reason for their mention, if specified.'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 14:32:24,401 - INFO - Performing query...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot response for query:  Could you outline all individuals from law enforcement, especially police officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys referenced in the transcript and their context of mention, if defined?\n",
      "[{'Officer Name': 'Stewart', 'Officer Context': 'Stewart escorted BORDERE to the\n",
      "homicide office and inquired about his relationship with ROBERT JONES. Stewart also\n",
      "interviewed DONALD OLIVER regarding the information provided by the informant. Based\n",
      "on the investigation, Stewart elected to arrest JONES for the murder of STOTT, and\n",
      "OLIVER and BORDERE were arrested as accessories to murder after the fact.', 'Officer\n",
      "Title': '', 'Query': 'Could you outline all individuals from law enforcement,\n",
      "especially police officers, sergeants, lieutentants, captains, detectives, homicide\n",
      "units, crime lab personnel, and district attorneys referenced in the transcript and\n",
      "their context of mention, if defined?'}, {'Officer Name': 'McCord', 'Officer\n",
      "Context': 'McCord contacted Stewart to inform him that PERNELL HARRIS had arrived at\n",
      "the homicide office. Stewart instructed McCord to interview PAPRIS about the events\n",
      "of the homicide and the conversation that occurred at the barroom.', 'Officer Title':\n",
      "'c', 'Query': 'Could you outline all individuals from law enforcement, especially\n",
      "police officers, sergeants, lieutentants, captains, detectives, homicide units, crime\n",
      "lab personnel, and district attorneys referenced in the transcript and their context\n",
      "of mention, if defined?'}, {'Officer Name': 'Canal', 'Officer Context': 'Stewart met\n",
      "with Lt. L. J. Canal, Commander of the Homicide Section, and learned that a\n",
      "Homicide/Robbery Task Force was organized to focus on certain robberies related to\n",
      "the current investigation. The task force included Lt. Martin Venezia (Commander),\n",
      "Sat: Craig Rodrigue (Supervisor), Det. James Stewart (Homicide), and Det. Herman\n",
      "Cade, Det. Yvonne Farve, and Det. Michael Sposito (General Assignment).', 'Officer\n",
      "Title': 'C', 'Query': 'Could you outline all individuals from law enforcement,\n",
      "especially police officers, sergeants, lieutentants, captains, detectives, homicide\n",
      "units, crime lab personnel, and district attorneys referenced in the transcript and\n",
      "their context of mention, if defined?'}, {'Officer Name': 'Jyles', 'Officer Context':\n",
      "'Jyles, the lessee of the apartment at 3550 Desire Parkway, allowed the officers to\n",
      "search the residence without obtaining a search warrant.', 'Officer Title': 'l',\n",
      "'Query': 'Could you outline all individuals from law enforcement, especially police\n",
      "officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab\n",
      "personnel, and district attorneys referenced in the transcript and their context of\n",
      "mention, if defined?'}]\n",
      "\n",
      "Bot response for query:  Please pinpoint all law enforcement associates, mainly police officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys cited in the transcript and specify their mention context, if outlined.\n",
      "[{'Officer Name': 'Det. James Stewart', 'Officer Context': 'Det. James Stewart is\n",
      "mentioned multiple times in the court transcripts. He is identified as the reporting\n",
      "officer and detective in charge of the homicide investigation. He instructs Les.\n",
      "Norman McCord to interview PAPRIS about the events of the homicide and the\n",
      "conversation pertaining to it that occurred at the barroom. Det. James Stewart also\n",
      "meets with Lt. L. J. Canal, Commander of the Homicide Section, to discuss the\n",
      "formation of a Homicide/Robbery Task Force. In addition, he interviews Donald Oliver\n",
      "and Border regarding their relationship with Robert Jones and the conversation in the\n",
      "barroom. Det. James Stewart is involved in the arrest of Jones, Oliver, and Border as\n",
      "accessories to murder after the fact.', 'Officer Title': '', 'Query': 'Please\n",
      "pinpoint all law enforcement associates, mainly police officers, sergeants,\n",
      "lieutentants, captains, detectives, homicide units, crime lab personnel, and district\n",
      "attorneys cited in the transcript and specify their mention context, if outlined.'},\n",
      "{'Officer Name': 'Lt. J. Canal', 'Officer Context': 'Lt. L. J. Canal is mentioned as\n",
      "the Commander of the Homicide Section. He informs Det. James Stewart about the\n",
      "formation of a Homicide/Robbery Task Force to focus on certain robberies and locate\n",
      "witnesses and evidence relating to the murder of Stott.', 'Officer Title': 'L',\n",
      "'Query': 'Please pinpoint all law enforcement associates, mainly police officers,\n",
      "sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel,\n",
      "and district attorneys cited in the transcript and specify their mention context, if\n",
      "outlined.'}, {'Officer Name': 'Lt. Martin Venezia', 'Officer Context': 'Lt. Martin\n",
      "Venezia is mentioned as the Commander of the Homicide/Robbery Task Force.', 'Officer\n",
      "Title': 'L', 'Query': 'Please pinpoint all law enforcement associates, mainly police\n",
      "officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab\n",
      "personnel, and district attorneys cited in the transcript and specify their mention\n",
      "context, if outlined.'}, {'Officer Name': 'Sat: Craig Rodrigue', 'Officer Context':\n",
      "'Sat: Craig Rodrigue is mentioned as the supervisor of the Homicide/Robbery Task\n",
      "Force.', 'Officer Title': 'C', 'Query': 'Please pinpoint all law enforcement\n",
      "associates, mainly police officers, sergeants, lieutentants, captains, detectives,\n",
      "homicide units, crime lab personnel, and district attorneys cited in the transcript\n",
      "and specify their mention context, if outlined.'}, {'Officer Name': 'Det. Herman\n",
      "Cade', 'Officer Context': 'Det. Herman Cade is mentioned as a member of the\n",
      "Homicide/Robbery Task Force.', 'Officer Title': 'C', 'Query': 'Please pinpoint all\n",
      "law enforcement associates, mainly police officers, sergeants, lieutentants,\n",
      "captains, detectives, homicide units, crime lab personnel, and district attorneys\n",
      "cited in the transcript and specify their mention context, if outlined.'}, {'Officer\n",
      "Name': 'Det. Yvonne Farve', 'Officer Context': 'Det. Yvonne Farve is mentioned as a\n",
      "member of the Homicide/Robbery Task Force.', 'Officer Title': '', 'Query': 'Please\n",
      "pinpoint all law enforcement associates, mainly police officers, sergeants,\n",
      "lieutentants, captains, detectives, homicide units, crime lab personnel, and district\n",
      "attorneys cited in the transcript and specify their mention context, if outlined.'},\n",
      "{'Officer Name': 'Det: MichaeSposito', 'Officer Context': 'Det: Michael Sposito is\n",
      "mentioned as a member of the Homicide/Robbery Task Force.', 'Officer Title': 'c',\n",
      "'Query': 'Please pinpoint all law enforcement associates, mainly police officers,\n",
      "sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel,\n",
      "and district attorneys cited in the transcript and specify their mention context, if\n",
      "outlined.'}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2023-07-10 14:34:40,734 - INFO - CSV output for Alexander_Betty Neff Police Reports including composite.docx already exists. Skipping...\n",
      "2023-07-10 14:34:40,736 - INFO - CSV output for Hines-Robinson NOPD Supplemental Report.docx already exists. Skipping...\n",
      "2023-07-10 14:34:40,737 - INFO - CSV output for Kenner Police Arrest Report.docx already exists. Skipping...\n",
      "2023-07-10 14:34:40,738 - INFO - CSV output for Montegut Police Report.docx already exists. Skipping...\n",
      "2023-07-10 14:34:40,739 - INFO - CSV output for NOPD report - only - better copy recd 1-7-14 in file no. 273-259.docx already exists. Skipping...\n",
      "2023-07-10 14:34:40,741 - INFO - CSV output for Police Report.docx already exists. Skipping...\n",
      "2023-07-10 14:34:40,742 - INFO - Processing Word document: ../../data/convictions/evaluate/reports\\~$exander_Betty Neff Police Reports including composite.docx\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 230\u001b[0m\n\u001b[0;32m    226\u001b[0m     answer_query_for_each_doc(embeddings)\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 230\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[6], line 226\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m    225\u001b[0m     embeddings \u001b[39m=\u001b[39m generate_hyde()\n\u001b[1;32m--> 226\u001b[0m     answer_query_for_each_doc(embeddings)\n",
      "Cell \u001b[1;32mIn[6], line 192\u001b[0m, in \u001b[0;36manswer_query_for_each_doc\u001b[1;34m(embeddings)\u001b[0m\n\u001b[0;32m    189\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(doc_directory, file_name)\n\u001b[0;32m    190\u001b[0m output_data \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 192\u001b[0m db \u001b[39m=\u001b[39m process_single_document(file_path, embeddings)\n\u001b[0;32m    194\u001b[0m \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries:\n\u001b[0;32m    195\u001b[0m     officer_data, _ \u001b[39m=\u001b[39m get_response_from_query(db, query)\n",
      "Cell \u001b[1;32mIn[6], line 64\u001b[0m, in \u001b[0;36mprocess_single_document\u001b[1;34m(file_path, embeddings)\u001b[0m\n\u001b[0;32m     61\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing Word document: \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m loader \u001b[39m=\u001b[39m Docx2txtLoader(file_path)\n\u001b[1;32m---> 64\u001b[0m text \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m     65\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mText loaded from Word document: \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[39m=\u001b[39m\u001b[39m3000\u001b[39m, chunk_overlap\u001b[39m=\u001b[39m\u001b[39m1500\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\document_loaders\\word_document.py:55\u001b[0m, in \u001b[0;36mDocx2txtLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load given path as single page.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdocx2txt\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     54\u001b[0m     Document(\n\u001b[1;32m---> 55\u001b[0m         page_content\u001b[39m=\u001b[39mdocx2txt\u001b[39m.\u001b[39;49mprocess(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_path),\n\u001b[0;32m     56\u001b[0m         metadata\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path},\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\docx2txt\\docx2txt.py:76\u001b[0m, in \u001b[0;36mprocess\u001b[1;34m(docx, img_dir)\u001b[0m\n\u001b[0;32m     73\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     75\u001b[0m \u001b[39m# unzip the docx in memory\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m zipf \u001b[39m=\u001b[39m zipfile\u001b[39m.\u001b[39;49mZipFile(docx)\n\u001b[0;32m     77\u001b[0m filelist \u001b[39m=\u001b[39m zipf\u001b[39m.\u001b[39mnamelist()\n\u001b[0;32m     79\u001b[0m \u001b[39m# get header text\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m# there can be 3 header files in the zip\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1299\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m-> 1299\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_RealGetContents()\n\u001b[0;32m   1300\u001b[0m     \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1301\u001b[0m         \u001b[39m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m         \u001b[39m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_didModify \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayyubi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1366\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[39mraise\u001b[39;00m BadZipFile(\u001b[39m\"\u001b[39m\u001b[39mFile is not a zip file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1366\u001b[0m     \u001b[39mraise\u001b[39;00m BadZipFile(\u001b[39m\"\u001b[39m\u001b[39mFile is not a zip file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1367\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1368\u001b[0m     \u001b[39mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import textwrap\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "from summarizer import Summarizer\n",
    "\n",
    "\n",
    "def summarize_context(context):\n",
    "    model = Summarizer()\n",
    "    result = model(context, min_length=60)\n",
    "    summary = \"\".join(result)\n",
    "    return summary\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "query_memory = []\n",
    "\n",
    "\n",
    "def generate_hyde():\n",
    "    llm = OpenAI()\n",
    "    prompt_template = \"\"\"\n",
    "    You're an AI assistant specializing in criminal justice research. \n",
    "    Your main focus is on identifying the names and providing detailed context of mention for each law enforcement personnel. \n",
    "    This includes police officers, detectives, deupties, lieutenants, sergeants, captains, technicians, and district attorneys, \n",
    "    as described in court transcripts.\n",
    "    Be aware that the titles \"Detective\" and \"Officer\" might be used interchangeably.\n",
    "    Be aware that the titles \"Technician\" and \"Tech\" might be used interchangeably.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Roles and Responses:\"\"\"\n",
    "    prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
    "\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    base_embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    embeddings = HypotheticalDocumentEmbedder(\n",
    "        llm_chain=llm_chain, base_embeddings=base_embeddings\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def process_single_document(file_path, embeddings):\n",
    "    logger.info(f\"Processing Word document: {file_path}\")\n",
    "\n",
    "    loader = Docx2txtLoader(file_path)\n",
    "    text = loader.load()\n",
    "    logger.info(f\"Text loaded from Word document: {file_path}\")\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=1500)\n",
    "    docs = text_splitter.split_documents(text)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    return db\n",
    "\n",
    "\n",
    "def clean_name(officer_name):\n",
    "    return re.sub(\n",
    "        r\"(Detective|Officer|Deputy|Captain|[CcPpLl]|Sergeant|Lieutenant|Techn?i?c?i?a?n?)\\.?\\s+\",\n",
    "        \"\",\n",
    "        officer_name,\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_officer_data(formatted_response):\n",
    "    officer_data = []\n",
    "    response_lines = formatted_response.split(\"\\n\")\n",
    "\n",
    "    for line in response_lines:\n",
    "        if line.startswith(\"Officer Name\"):\n",
    "            officer_name = line.split(\":\", 1)[1].strip()\n",
    "            officer_title = re.search(\n",
    "                r\"(Detective|Officer|Deputy|Captain|[CcPpLl]|Sergeant|Lieutenant|Techn?i?c?i?a?n?)\\.?\",\n",
    "                officer_name,\n",
    "            )\n",
    "            if officer_title:\n",
    "                officer_title = officer_title.group()\n",
    "            else:\n",
    "                officer_title = \"\"\n",
    "            officer_name = clean_name(officer_name)\n",
    "        elif line.startswith(\"Officer Context\"):\n",
    "            split_line = line.split(\":\", 1)\n",
    "            if len(split_line) > 1:\n",
    "                officer_context = split_line[1].strip()\n",
    "            else:\n",
    "                officer_context = \"\"  # Or any default value you want\n",
    "            officer_data.append(\n",
    "                {\n",
    "                    \"Officer Name\": officer_name,\n",
    "                    \"Officer Context\": officer_context,\n",
    "                    \"Officer Title\": officer_title,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return officer_data\n",
    "\n",
    "\n",
    "def get_response_from_query(db, query, k=3):\n",
    "    logger.info(\"Performing query...\")\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "    ### add investigator, ex: \"Orleans Parish Coroner's Office Investigator Purnell Lewis\" - 05 NOPD Supplemental Report \n",
    "    ### add crime lab! technician\n",
    "    ### need to add abbreviations to the prompt such as cpl., sgt., off.\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"docs\"],\n",
    "        template=\"\"\"\n",
    "        As an AI assistant, my role is to meticulously identify the names and provide a detailed explanation of the situations and interactions \n",
    "        in which each law enforcement personnel was mentioned in the court transcripts. \n",
    "\n",
    "        Query: {question}\n",
    "\n",
    "        Court Transcripts: {docs}\n",
    "\n",
    "        The response will contain:\n",
    "\n",
    "        1) The name of a law enforcement personnel. Law enforcement names will include be prefixed with the titles officer,\n",
    "           detective, deupty, lieutenant, sergeant, captain, or technician. Only identify law enforcement personnel.\n",
    "           Please prefix the name with \"Officer Name: \". \n",
    "        \n",
    "        2)  If available, a detailed explanation of the situation and interactions involving the identified personnel and the context of their mention.\n",
    "            Please prefix this information with \"Officer Context: \". \n",
    "\n",
    "        Continue this pattern, for each officer and each context, until all law enforcement personnel are identified. \n",
    "\n",
    "        Guidelines for the AI assistant:\n",
    "\n",
    "        - Derive responses from factual information found within the transcript.\n",
    "        - If the context of an identified person's mention is not clear in the transcript, provide their name and note that the context is not specified.\n",
    "        - If there is insufficient information to answer the query, simply respond with \"Insufficient information to answer the query\".\n",
    "    \"\"\",\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    response = chain.run(question=query, docs=docs_page_content, temperature=0)\n",
    "\n",
    "    formatted_response = \"\"\n",
    "    officers = response.split(\"Officer Name:\")\n",
    "    for i, officer in enumerate(officers):\n",
    "        if officer.strip() != \"\":\n",
    "            formatted_response += f\"Officer Name {i}:{officer.replace('Officer Context:', 'Officer Context ' + str(i) + ':')}\\n\\n\"\n",
    "\n",
    "    officer_data = extract_officer_data(formatted_response)\n",
    "    return officer_data, docs\n",
    "\n",
    "\n",
    "queries = [\n",
    "    \"Enumerate all law enforcement personnel, including police officers, sergeants, lieutentants, captains, detectives, homicide officers, crime lab personnel, and district attorneys from the transcript and provide the context of their mention, if available.\",\n",
    "    \"Can you list all individuals related to law enforcement such as police officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys mentioned in the transcript and elaborate on the context of their mention?\",\n",
    "    \"Please produce a roster of all persons involved with law enforcement, including police officers,  sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys from the transcript and explain why they are mentioned, if stated.\",\n",
    "    \"Identify all the law enforcement entities, notably police officers, sergeants, lieutentants, captains,  detectives, homicide units, crime lab personnel, and district attorneys stated in the transcript and describe the reason for their mention, if specified.\",\n",
    "    \"Could you outline all individuals from law enforcement, especially police officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys referenced in the transcript and their context of mention, if defined?\",\n",
    "    \"Please pinpoint all law enforcement associates, mainly police officers, sergeants, lieutentants, captains, detectives, homicide units, crime lab personnel, and district attorneys cited in the transcript and specify their mention context, if outlined.\",\n",
    "]\n",
    "\n",
    "\n",
    "def answer_query_for_each_doc(embeddings):\n",
    "    doc_directory = \"../../data/convictions/evaluate/reports\"\n",
    "\n",
    "    for file_name in os.listdir(doc_directory):\n",
    "        if file_name.endswith(\".docx\"):\n",
    "            csv_output_path = os.path.join(doc_directory, f\"{file_name}.csv\")\n",
    "            if os.path.exists(csv_output_path):\n",
    "                logger.info(f\"CSV output for {file_name} already exists. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(doc_directory, file_name)\n",
    "            output_data = []\n",
    "\n",
    "            db = process_single_document(file_path, embeddings)\n",
    "\n",
    "            for query in queries:\n",
    "                officer_data, _ = get_response_from_query(db, query)\n",
    "                for item in officer_data:\n",
    "                    item[\"Query\"] = query\n",
    "                output_data.extend(officer_data)\n",
    "\n",
    "                print(\"Bot response for query: \", query)\n",
    "                print(textwrap.fill(str(officer_data), width=85))\n",
    "                print()\n",
    "\n",
    "            ### need to handle for multiple titles associated with a name\n",
    "\n",
    "            output_df = pd.DataFrame(output_data)\n",
    "            officer_title_df = output_df[\n",
    "                [\"Officer Name\", \"Officer Title\"]\n",
    "            ].drop_duplicates()\n",
    "            output_df = (\n",
    "                output_df.groupby(\"Officer Name\")[\"Officer Context\"]\n",
    "                .apply(\"; \".join)\n",
    "                .reset_index()\n",
    "            )\n",
    "            output_df[\"Officer Context\"] = output_df[\"Officer Context\"].apply(\n",
    "                summarize_context\n",
    "            )\n",
    "            output_df = pd.merge(\n",
    "                output_df, officer_title_df, on=\"Officer Name\", how=\"outer\"\n",
    "            )\n",
    "            output_df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "    embeddings = generate_hyde()\n",
    "    answer_query_for_each_doc(embeddings)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
